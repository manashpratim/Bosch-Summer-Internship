{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAttackV1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPeKfrgpGsKbeoQzxCyCYAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/TextAttackV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFcTGmoHA2Vg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Data is available at https://drive.google.com/drive/folders/1NFYIaXjL8V5kvZo3g9JEafLQ3scslWic?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blWkPFjNArl_",
        "colab_type": "text"
      },
      "source": [
        "## **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1umEBQ5yZnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpP5qZ3szQt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "      \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/CMU_MOSI.zip\"\\\n",
        "      -O \"/content/mosi.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C55dFxRb2q_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzip the dataset\n",
        "!unzip -q '/content/mosi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV9Mn_V32I81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to get the file names. Inputs are path and name of the file to be saved\n",
        "def get_file_names(mypath,savefile):\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  onlyfiles = [f[:f.find('.')] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  with open(savefile, 'w') as f:\n",
        "    for item in onlyfiles:\n",
        "        f.write(item)\n",
        "        f.write('\\n')\n",
        "  return onlyfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoplXeS-hOiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specify the path and get the file\n",
        "mypath = '/content/Raw/Transcript/Segmented'\n",
        "files = get_file_names(mypath,'textfile.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrUNTc1FhRD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the processed transcripts and the labels\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/mosi_data/labels_joined.pickle', 'rb') as handle:\n",
        "    label= pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/mosi_data/text_data_joined.pickle', 'rb') as handle:\n",
        "    dic = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkF_Z4sVBAAs",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKpwb4b3hRJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the segments of the text data into a numpy array\n",
        "import numpy as np\n",
        "review = []\n",
        "for key in files:\n",
        "  review+=dic[key]\n",
        "review = np.array(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNTDwxhmhRhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the labels into a numpy array\n",
        "import numpy as np\n",
        "y = []\n",
        "for key in files:\n",
        "    y+=label[key]\n",
        "y = np.array(y)\n",
        "\n",
        "y[y>0]=1        #Convert labels to binary\n",
        "y[y<0]=0\n",
        "\n",
        "y=y.astype(int)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RUwnC19hR1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to generate train-test split. Arguments are text data,labels and split_size (0.8 mean 80:20 train-test split)\n",
        "def split_data(text,labels,split_size=0.8):\n",
        "  import numpy as np  \n",
        "  train_length =int(len(labels)*split_size)\n",
        "  test_length =int(len(labels)-train_length)\n",
        "  idx = np.random.permutation(labels.shape[0])\n",
        "  text = text[idx]\n",
        "  labels = labels[idx]\n",
        "  text_train = text[:train_length]\n",
        "  text_val = text[train_length:]\n",
        "  labels_train = labels[:train_length]\n",
        "  labels_val = labels[train_length:]\n",
        "  \n",
        "  return text_train,text_val,labels_train,labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzHfm3cIhRyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get train-test split\n",
        "train_reviews,  val_reviews, train_labels, val_labels = split_data(review,y,0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y7cr4UKhRs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the text data. Similar to the audio data, segments of the text data are paddded to have same length\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 581\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_len=5000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_len+1,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(review)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "print('Size of Vocabulary: ',vocab_size)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_reviews)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_labels=np.expand_dims(train_labels, axis=1)\n",
        "val_labels=np.expand_dims(val_labels, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ScxQDv_hRqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Statistics\n",
        "print('Dimension of Training  Text Data: ',train_padded.shape)\n",
        "print('Dimension of Test Text Data: ',val_padded.shape)\n",
        "print('Dimension of Training Labels: ',train_labels.shape)\n",
        "print('Dimension of Validation Labels: ',val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6tIDuS2hRn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download Glove Wiki Embeddings\n",
        "!wget --no-check-certificate \\\n",
        "      \"http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\"\\\n",
        "      -O \"/content/drive/My Drive/mosi_data/globe6B.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKgbQXMjhRlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the downloaded embeddings\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/globe6B.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLASCG1BhRek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the embeddings. There are 4 dimensions to choose from. I used 300 dimensional embeddings. \n",
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7x9lRafhRb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map the embeddings with the words of the text data\n",
        "embedding_dim = 300\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GboaOvjpBF9_",
        "colab_type": "text"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbHHADd3hRWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_wdttBkhRT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(layers.Layer):\n",
        "    def __init__(self, maxlen, embed_dim, vocab_size,embeddings_matrix,num_heads):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        self.embed = tf.keras.layers.Embedding(vocab_size+1, embed_dim,  input_length=maxlen, weights = [embeddings_matrix], trainable = False)\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "\n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))\n",
        "        self.lstm2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.4)\n",
        "        self.dropout5 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dropout6 = tf.keras.layers.Dropout(0.4)\n",
        "        self.pool     =  tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
        "        self.dense2 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
        "        self.out = tf.keras.layers.Dense(2, activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        inputs = self.embed(inputs) \n",
        "        inputs = self.dropout6(inputs)\n",
        "        attn_output = self.att(inputs)\n",
        "        x = inputs + attn_output\n",
        "        x = self.dropout1(x)\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout4(x)\n",
        "        out = self.out(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJLKUFpXhRR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 3108\n",
        "maxlen = 581\n",
        "embed_dim = 300  # Embedding size for each token\n",
        "num_heads = 10  # Number of attention heads\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "transformer_block = Transformer(maxlen, embed_dim, vocab_size,embeddings_matrix,num_heads)\n",
        "outputs = transformer_block(inputs)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzgVVE2OhRPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True,monitor='val_accuracy', min_delta=1e-4,mode='max')\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_padded, train_labels, batch_size=32, epochs=50, validation_split=0.15,shuffle=True,callbacks=[reduce,earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSPAZN-nuAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test Accuracy\n",
        "results = model.evaluate(x=val_padded,y=val_labels)\n",
        "print('Test Set Performance: ',results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRXlDzMiBOYk",
        "colab_type": "text"
      },
      "source": [
        "## **Attack**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-SlD8lhRHW",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english'))\n",
        "from absl import logging\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "mode = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "\n",
        "def embed(input):\n",
        "  return mode(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPbqntVdHntW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "#model1 = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz (Unzipped Files)/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/fasttext_wiki.zip'\n",
        "model1 = KeyedVectors.load_word2vec_format('/content/wiki-news-300d-1M.vec', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX5T9A7_iIdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_word_saliency(model,val_reviews,val_padded,val_labels):\n",
        "    candidates = {}\n",
        "    outer = tqdm(total=len(val_reviews), desc='Evaluating Word Saliency', position=0)\n",
        "    for j,sent in enumerate(val_reviews):\n",
        "        outer.update(1)\n",
        "        sent = sent.split()\n",
        "        score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "        pred = np.argmax(score)\n",
        "\n",
        "        if pred==val_labels[j]:\n",
        "          mask = np.zeros(581)\n",
        "          mask[:len(sent)]=1\n",
        "          dic = {}\n",
        "          for i,word in enumerate(sent):\n",
        "            if word not in stop_words:\n",
        "              mask[i] = 0\n",
        "              inp = mask*val_padded[j]\n",
        "              score_new = model.predict(inp.reshape(1,-1))[0]\n",
        "              pred_new = np.argmax(score_new)\n",
        "              if pred_new == pred:\n",
        "                imp = score[pred] - score_new[pred_new]\n",
        "              else:\n",
        "                  imp = (score[pred] - score_new[pred]) + (score_new[pred_new] - score[pred_new])\n",
        "              mask[i] = 1\n",
        "              if imp>0:\n",
        "                dic[word] = imp\n",
        "          if dic:\n",
        "            k = sorted(dic.keys(),key = dic.get,reverse=True)\n",
        "            if len(k)>3:\n",
        "              candidates[j] = k[:3]\n",
        "            else:\n",
        "              candidates[j] = k\n",
        "\n",
        "    return candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShAEFCoSiSEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_words(model,val_reviews,val_padded,val_labels,candidates,model1,embed):\n",
        "      \n",
        "      new_candidates = {}\n",
        "\n",
        "      outer = tqdm(total=len(candidates), desc='Finding Similar Words', position=0)\n",
        "      for j,sent in enumerate(val_reviews):\n",
        "        if j in candidates:\n",
        "            outer.update(1)\n",
        "            sent = sent.split()\n",
        "            dic = {}\n",
        "            score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "            pred = np.argmax(score)\n",
        "            for i,word in enumerate(sent):\n",
        "              if word in candidates[j]:\n",
        "                n = []\n",
        "                try:\n",
        "                  l = model1.most_similar(word,topn=50)\n",
        "                except:\n",
        "                  pass\n",
        "\n",
        "                mini = float('inf')\n",
        "                we = None \n",
        "                for w in l:\n",
        "                  if w[0].lower()!=word:\n",
        "                    arr = sent[:]\n",
        "                    arr[i] = w[0].lower()\n",
        "                    k = tokenizer.texts_to_sequences([\" \".join(arr)])\n",
        "                    inp = pad_sequences(k, maxlen=581, padding='post', truncating='post')\n",
        "                    score_new = model.predict(inp)[0]\n",
        "                    pred_new = np.argmax(score_new)\n",
        "                    if pred_new !=pred:\n",
        "                      message_embeddings = embed([\" \".join(arr),\" \".join(sent)])\n",
        "                      score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                      if score1>0.6:\n",
        "                          n.append(w[0].lower())\n",
        "                    else:\n",
        "                      if score_new[pred]<mini:\n",
        "                            mini = score_new[pred]\n",
        "                            we = w[0].lower()\n",
        "                if we:\n",
        "                  arr = sent[:]\n",
        "                  arr[i] = we\n",
        "                  message_embeddings = embed([\" \".join(arr),\" \".join(sent)])\n",
        "                  score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                  if score1>0.6:\n",
        "                    n.append(we)\n",
        "                if n:\n",
        "                  dic[word] = n[:]\n",
        "            if dic:\n",
        "                new_candidates[j] = dic \n",
        "\n",
        "      return new_candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRsJqyJjzJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_adversary(model,val_reviews,val_padded,val_labels,new_candidates,embed):\n",
        "    adversary = {}\n",
        "\n",
        "    outer = tqdm(total=len(new_candidates), desc='Training', position=0)\n",
        "    for j,sent in enumerate(val_reviews):\n",
        "      if j in new_candidates:\n",
        "        outer.update(1)\n",
        "        sent = sent.split()\n",
        "        score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "        pred = np.argmax(score)\n",
        "        a = []\n",
        "        arr = sent[:]\n",
        "        flag = 0\n",
        "        for i,word in enumerate(sent):\n",
        "          if word in new_candidates[j]:\n",
        "            \n",
        "            mini = float('inf')\n",
        "            we = None\n",
        "            \n",
        "            for w in new_candidates[j][word]:\n",
        "              if w:\n",
        "                s = arr[i]\n",
        "                arr[i] = w.lower()\n",
        "                k = tokenizer.texts_to_sequences([\" \".join(arr)])\n",
        "                inp = pad_sequences(k, maxlen=581, padding='post', truncating='post')\n",
        "                score_new = model.predict(inp)[0]\n",
        "                pred_new = np.argmax(score_new)\n",
        "                if pred_new !=pred:\n",
        "                  arr1 = sent[:]\n",
        "                  arr1[i] = w.lower()\n",
        "                  message_embeddings = embed([\" \".join(arr1),\" \".join(sent)])\n",
        "                  score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                  if score1>0.6:\n",
        "                      arr = sent[:]\n",
        "                      arr[i] = w.lower()\n",
        "                      flag=1\n",
        "                      break\n",
        "                else:\n",
        "                    \n",
        "                    if  abs(score[pred] - score_new[pred])>0.4:\n",
        "                        arr1 = sent[:]\n",
        "                        arr1[i] = w.lower()\n",
        "                        message_embeddings = embed([\" \".join(arr1),\" \".join(sent)])\n",
        "                        score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                        if score1>0.6:\n",
        "                              arr = sent[:]\n",
        "                              arr[i] = w.lower()\n",
        "                              flag = 1\n",
        "                              break\n",
        "                    else:\n",
        "                      arr[i] = s\n",
        "                      if score_new[pred]<mini:\n",
        "                          mini = score_new[pred]\n",
        "                          we = w.lower()\n",
        "            if flag:\n",
        "              break\n",
        "            if we:\n",
        "              arr[i] = we\n",
        "        adversary[j] = \" \".join(arr)\n",
        "\n",
        "    adver = []\n",
        "\n",
        "    for i in range(len(val_reviews)):\n",
        "      if i in adversary:\n",
        "        adver.append(adversary[i])\n",
        "      else:\n",
        "        adver.append(val_reviews[i])\n",
        "\n",
        "    return adver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TQEP9dgl8qL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candidates = evaluate_word_saliency(model,val_reviews,val_padded,val_labels)\n",
        "new_candidates = find_similar_words(model,val_reviews,val_padded,val_labels,candidates,model1,embed)\n",
        "adversary = generate_adversary(model,val_reviews,val_padded,val_labels,new_candidates,embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvE9yYNSlfyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_seq = tokenizer.texts_to_sequences(adversary)\n",
        "val_pad = pad_sequences(val_seq, maxlen=581, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ktMs0hbl7kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(x=val_padded,y=val_labels)\n",
        "print('Test Set Performance: ',results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjQAny63mZ4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(x=val_pad,y=val_labels)\n",
        "print('Test Set Performance after Attack: 'results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}