{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNkp2ymk1PJtyLEQn16juKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/VideoV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8LS9yWfFDwC",
        "colab_type": "text"
      },
      "source": [
        "### Data is available at https://drive.google.com/drive/folders/1NFYIaXjL8V5kvZo3g9JEafLQ3scslWic?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AsnZTBPFhEY",
        "colab_type": "text"
      },
      "source": [
        "## **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtAJjRhhPM0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4LPp2sBS7nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/mosi_data/mosi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj-sk1clSw_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_file_names(mypath,savefile):\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  onlyfiles = [f[:f.find('.')] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  with open(savefile, 'w') as f:\n",
        "    for item in onlyfiles:\n",
        "        f.write(item)\n",
        "        f.write('\\n')\n",
        "  return onlyfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stZY-cJrSz7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mypath = '/content/Raw/Transcript/Segmented'\n",
        "files = get_file_names(mypath,'textfile.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCXN4IvpSVKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/mosi_data/video_frames_joined.pickle', 'rb') as handle:\n",
        "    nd = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/mosi_data/video_features.pickle', 'rb') as handle:\n",
        "    dic3 = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/mosi_data/video_features_dense.pickle', 'rb') as handle:\n",
        "    dic2 = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/mosi_data/labels_joined.pickle', 'rb') as handle:\n",
        "    labels = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHbx2nRlFmgA",
        "colab_type": "text"
      },
      "source": [
        "## **Processing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7uvj3aUGgHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block pads the video features so that each segments have same length. I use zero padding. This is the data for model 1.\n",
        "# The videos were sampled at 0.5s. The features were extracted using MTCNN and VGG Face 2. The dimension of frames passed to the models were 100x100x3\n",
        "video_data = []\n",
        "#maximum = float('-inf')\n",
        "max_pad_len = 77                            #max length of a sequence\n",
        "                          \n",
        "\n",
        "for key in files:\n",
        "  for l in dic3[key]:\n",
        "    l = np.array(l)\n",
        "    if len(l)>0:\n",
        "      #maximum = max(maximum,l.shape[0])\n",
        "      pad_width = max_pad_len - l.shape[0]\n",
        "      mfcc = np.pad(l.T, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "      video_data.append(mfcc)\n",
        "    else:                                     # This else statement is for the VGGish features data. They have 28 bad frames. It does not affect the MFCC data\n",
        "      f = np.random.rand(512,77)               \n",
        "      video_data.append(f)\n",
        "\n",
        "video_data = np.array(video_data)\n",
        "video_data= video_data.reshape(video_data.shape[0], 512, 77,1)          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2-JmgM-SsXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block pads the video frames so that each segments have same length. I use zero padding. This is the data for Model 2.\n",
        "video_data = []\n",
        "maximum = float('-inf')\n",
        "\n",
        "for key in files:\n",
        "  for l in nd[key]:\n",
        "        video_data.append(l)\n",
        "import tensorflow as tf\n",
        "video_data=tf.keras.preprocessing.sequence.pad_sequences(video_data, maxlen=40, dtype='float32', padding='post', truncating='post',value=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_BZdLZIHp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This block pads the video features so that each segments have same length. I use zero padding. This is the data for model 3.\n",
        "#The videos were sampled at 0.03s. The features were extracted using VGG Face 2. The dimension of frames passed to the models were 224x224x3 \n",
        "# This block pads the audio features so that each segments have same length. I use zero padding\n",
        "video_data = []\n",
        "\n",
        "for key in files:\n",
        "  for l in dic2[key]:            \n",
        "      video_data.append(l)\n",
        "\n",
        "import tensorflow as tf\n",
        "video_data = tf.keras.preprocessing.sequence.pad_sequences(video_data, maxlen=142, dtype='float32', padding='post', truncating='post',value=0.0)\n",
        "video_data = video_data[:,:,:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoMaIqt4Ulv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the labels into a numpy array\n",
        "import numpy as np\n",
        "y = []\n",
        "for key in files:\n",
        "    y+=labels[key]\n",
        "y = np.array(y)\n",
        "\n",
        "#For regression, do not execute any of the lines below\n",
        "\n",
        "y[y>0]=1        #Convert labels to binary\n",
        "y[y<0]=0\n",
        "\n",
        "y=y.astype(int)   \n",
        "\n",
        "#ref = {-3:0,-2:1,-1:2,0:3,1:4,2:5,3:6}         #Uncomment the following three lines for 7 class classification\n",
        "#for i,num in enumerate(y):\n",
        "#  y[i] = ref[num]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMrBsszVU2bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(data,labels,split_size=0.8):\n",
        "  import numpy as np  \n",
        "  train_length =int(len(labels)*split_size)\n",
        "  test_length =int(len(labels)-train_length)\n",
        "  idx = np.random.permutation(labels.shape[0])\n",
        "  data = data[idx]\n",
        "  labels = labels[idx]\n",
        "  data_train = data[:train_length]\n",
        "  data_val = data[train_length:]\n",
        "  labels_train = labels[:train_length]\n",
        "  labels_val = labels[train_length:]\n",
        "  \n",
        "  return data_train,data_val,labels_train,labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a6PujOBU4pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_train,video_val,labels_train,labels_val = split_data(video_data,y,split_size=0.8)\n",
        "del video_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKJcq-D0G7fW",
        "colab_type": "text"
      },
      "source": [
        "## **Model 1 (Baseline)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEdgp6iUG-Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "#from keras import regularizers\n",
        "\n",
        "model=tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(512,77,1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(256,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    #tf.keras.layers.Dense(1)\n",
        "    #tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "    tf.keras.layers.Dense(7,activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpq1PFc-HRW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')  #to reduce learning rate by factor of 0.1 if model performance degrades for 10 (patience) epochs.  \n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')  #early stopping if performance of model degrades for 10 epochs\n",
        "\n",
        "#Uncomment one of the next three lines at a time\n",
        "#model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy',f1_score])                #Binary classification\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model2.compile(loss=\"mean_absolute_error\",optimizer='adam',metrics=[\"mean_absolute_error\"])             #Regression\n",
        "\n",
        "# I am training for 50 epochs with a batch size of 256. Set verbose to 2 for no training details and 0 for more training details.\n",
        "num_epochs = 50\n",
        "history=model.fit(video_train, \n",
        "                    labels_train, \n",
        "                    epochs=num_epochs, \n",
        "                    batch_size=256, \n",
        "                    validation_data=(video_val,labels_val),\n",
        "                    callbacks=[reduce],\n",
        "                    shuffle = True,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1LCfXv9F2m6",
        "colab_type": "text"
      },
      "source": [
        "## **Model 2 (RAW)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-LB7LU7UpOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# video model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "inp = Input(shape=(40, 64, 64, 3))\n",
        "x   = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(1,2,2),activation=\"relu\", padding=\"same\")(inp)\n",
        "x   = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(1,2,2),activation=\"relu\", padding=\"same\")(x)\n",
        "x   = tf.keras.layers.BatchNormalization()(x)\n",
        "x   = tf.keras.layers.Dropout(0.4)(x)\n",
        "x   = tf.keras.layers.Reshape((40, 16*16*64))(x)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x   = tf.keras.layers.BatchNormalization()(x)\n",
        "x   = tf.keras.layers.Dropout(0.4)(x)\n",
        "x  = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x   = tf.keras.layers.BatchNormalization()(x)\n",
        "x   = tf.keras.layers.Dropout(0.4)(x)\n",
        "x   = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x   = tf.keras.layers.Dropout(0.5)(x)\n",
        "out   = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "#out   = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
        "#out   = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = Model(inp,out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7cFBh_Ug9Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')\n",
        "\n",
        "#Uncomment one of the next three lines at a time               \n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])         #Binary classification\n",
        "#model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model.compile(loss=\"mean_absolute_error\",optimizer='rmsprop')             #Regression\n",
        "history=model.fit(video_train,labels_train, batch_size=32, epochs=80, shuffle=True,validation_data=(video_val,labels_val),callbacks=[reduce],use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqd82-B2KG-N",
        "colab_type": "text"
      },
      "source": [
        "## **Model 3 (Transformer)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfVQlIfAHkow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2ukhacoKYaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(layers.Layer):\n",
        "    def __init__(self, maxlen, embed_dim,num_heads):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "\n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))\n",
        "        self.lstm2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.4)\n",
        "        self.dropout5 = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "        self.pool     =  tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.bn1   = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
        "        self.bn3   = tf.keras.layers.BatchNormalization()\n",
        "        self.bn4   = tf.keras.layers.BatchNormalization()\n",
        "        self.bn5   = tf.keras.layers.BatchNormalization()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
        "        self.dense2 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
        "        self.out = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "        #self.out = tf.keras.layers.Dense(7, activation=\"softmax\")\n",
        "        #self.out = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        attn_output = self.att(inputs)\n",
        "        x = inputs + attn_output\n",
        "        x = self.dropout1(x)\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout5(x)\n",
        "        out = self.out(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXCeAKtAKngY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 142\n",
        "embed_dim = 500\n",
        "num_heads = 10\n",
        "inputs = layers.Input(shape=(maxlen,embed_dim))\n",
        "transformer_block = Transformer(maxlen, embed_dim,num_heads)\n",
        "outputs = transformer_block(inputs)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfE0rxmNK-IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')\n",
        "\n",
        "#Uncomment one of the next three lines at a time               \n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])         #Binary classification\n",
        "#model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model.compile(loss=\"mean_absolute_error\",optimizer='rmsprop')             #Regression\n",
        "history=model.fit(video_train,labels_train, batch_size=32, epochs=80, shuffle=True,validation_data=(video_val,labels_val),callbacks=[reduce],use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}