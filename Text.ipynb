{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNKOUDMOj2iJQTBUaWXh8SY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGh6EFWic8K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data is available at https://drive.google.com/drive/folders/1NFYIaXjL8V5kvZo3g9JEafLQ3scslWic?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy-64GNwGF6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7184f487-96cf-4d8a-a311-0914dcbca2e7"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWaXFaGYEkbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzip the dataset\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/mosi.zip'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTNEHXZ8JWwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to get the file names. Inputs are path and name of the file to be saved\n",
        "def get_file_names(mypath,savefile):\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  onlyfiles = [f[:f.find('.')] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  with open(savefile, 'w') as f:\n",
        "    for item in onlyfiles:\n",
        "        f.write(item)\n",
        "        f.write('\\n')\n",
        "  return onlyfiles"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjzjTwU9JYO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specify the path and get the file\n",
        "mypath = '/content/Raw/Transcript/Segmented'\n",
        "files = get_file_names(mypath,'textfile.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1dbPy64kgW7",
        "colab_type": "text"
      },
      "source": [
        "# **Extracting Text Data from Transcripts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqZOyGqOkoyA",
        "colab_type": "text"
      },
      "source": [
        "The extracted data is available at the link provided above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF61bU90Ktlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to process the transcripts and save them as pickle file. \n",
        "# Arguments are location of the transcripts, name of the files and the name of the file to be saved.\n",
        "def get_text_data_joined(mypath,files,savefile):\n",
        "  dic = {}\n",
        "  for file in files:\n",
        "      filename = mypath+'/' + file + '.annotprocessed'\n",
        "      text_file = open(filename, \"r\")\n",
        "      lines = text_file.read().split('\\n')\n",
        "      lines = lines[:-1]\n",
        "      dic[file] = []\n",
        "      for line in lines:\n",
        "        ind1 = line.find('_')+1\n",
        "        line = line[ind1:]\n",
        "        ind2 = line.find('_')+1\n",
        "        line = line[ind2:].strip()\n",
        "        dic[file].append(line.lower())\n",
        "  import pickle\n",
        "  with open(savefile, 'wb') as handle:\n",
        "         pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDguayUVL74j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the above function\n",
        "savefile = '/content/drive/My Drive/mosi_data/text_data_joined.pickle'\n",
        "dic = get_text_data_joined(mypath,files,savefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouoDWPRMk1sR",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKs_4-TrMmAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the processed transcripts and the labels\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/mosi_data/labels_joined.pickle', 'rb') as handle:\n",
        "    label= pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/mosi_data/text_data_joined.pickle', 'rb') as handle:\n",
        "    dic = pickle.load(handle)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrax9H42Ndrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the segments of the text data into a numpy array\n",
        "import numpy as np\n",
        "review = []\n",
        "for key in files:\n",
        "  review+=dic[key]\n",
        "review = np.array(review)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QB1pvNWOJBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the labels into a numpy array\n",
        "import numpy as np\n",
        "y = []\n",
        "for key in files:\n",
        "    y+=label[key]\n",
        "y = np.array(y)\n",
        "\n",
        "#y[y>0]=1        #Convert labels to binary\n",
        "#y[y<0]=0\n",
        "\n",
        "#y=y.astype(int)   # Execute this line for classification. Comment it for regression\n",
        "#ref = {-3:0,-2:1,-1:2,0:3,1:4,2:5,3:6}         #Uncomment the following three lines for 7 class classification\n",
        "#for i,num in enumerate(y):\n",
        "#  y[i] = ref[num]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFbIcwEomEv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the audio features\n",
        "with open('/content/drive/My Drive/mosi_data/audio_features_joined.pickle', 'rb') as handle:\n",
        "    dic2 = pickle.load(handle)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZO0r4sunpZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block pads the audio features so that each segments have same length. I use zero padding\n",
        "audio_data = []\n",
        "maximum = float('-inf')\n",
        "max_pad_len = 1639                            #max length of a sequence. For audio_features_joined (MFCC), use this\n",
        "#max_pad_len = 858                            #For audio_pretrained_features_joined (VGGish), use this. Uncomment the above\n",
        "\n",
        "for key in files:\n",
        "  for l in dic2[key]:\n",
        "\n",
        "    if len(l)>0:\n",
        "      #maximum = max(maximum,l.shape[0])\n",
        "      pad_width = max_pad_len - l.shape[0]\n",
        "      mfcc = np.pad(l.T, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "      audio_data.append(mfcc)\n",
        "    else:                                     # This else statement is for the VGGish features data. They have 28 bad frames. It does not affect the MFCC data\n",
        "      f = np.random.rand(128,858)               \n",
        "      audio_data.append(f)\n",
        "\n",
        "audio_data = np.array(audio_data)\n",
        "audio_data= audio_data.reshape(audio_data.shape[0], 57, 1639)             # For audio_features_joined\n",
        "#audio_data= audio_data.reshape(audio_data.shape[0], 128, 858)            # For audio_pretrained_features_joined"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCw9LAfZqifa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to generate train-test split. Arguments are text data,labels,audio features data and split_size (0.8 mean 80:20 train-test split)\n",
        "def split_data(text,audio,labels,split_size=0.8):\n",
        "  import numpy as np  \n",
        "  train_length =int(len(labels)*split_size)\n",
        "  test_length =int(len(labels)-train_length)\n",
        "  idx = np.random.permutation(labels.shape[0])\n",
        "  text = text[idx]\n",
        "  audio = audio[idx]\n",
        "  labels = labels[idx]\n",
        "  text_train = text[:train_length]\n",
        "  text_val = text[train_length:]\n",
        "  labels_train = labels[:train_length]\n",
        "  labels_val = labels[train_length:]\n",
        "  audio_train = audio[:train_length]\n",
        "  audio_val = audio[train_length:]\n",
        "  \n",
        "  return text_train,text_val,audio_train,audio_val,labels_train,labels_val"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EfYZzqCsnrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get train-test split\n",
        "train_reviews, val_reviews, train_audio, val_audio, train_labels, val_labels = split_data(review,audio_data,y,0.8)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXiv6wKKR4tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum sequence length of text data\n",
        "maximum = float('-inf')\n",
        "for s in review:\n",
        "    maximum = max(maximum,len(s))\n",
        "print(maximum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7_LJhsUNpMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "51e96aec-71f0-472f-f4d1-61c13879f3d4"
      },
      "source": [
        "# Preprocess the text data. Similar to the audio data, segments of the text data are paddded to have same length\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 581\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_len=5000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_len+1,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(review)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "print('Size of Vocabulary: ',vocab_size)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_reviews)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_labels=np.expand_dims(train_labels, axis=1)\n",
        "val_labels=np.expand_dims(val_labels, axis=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Vocabulary:  3108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7-McSITMp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Statistics\n",
        "print('Dimension of Training  Text Data: ',train_padded.shape)\n",
        "print('Dimension of Validation Text Data: ',val_padded.shape)\n",
        "print('Dimension of Training Labels: ',train_labels.shape)\n",
        "print('Dimension of Validation Labels: ',val_labels.shape)\n",
        "print('Dimension of Training Audio Data: ',train_audio.shape)\n",
        "print('Dimension of Validation Audio Data: ',val_audio.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1VdIclHTXIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download Glove Wiki Embeddings\n",
        "!wget --no-check-certificate \\\n",
        "      \"http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\"\\\n",
        "      -O \"/content/drive/My Drive/mosi_data/globe6B.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvljIHkqUHiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the downloaded embeddings\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/globe6B.zip'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r03B041VDGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the embeddings. There are 4 dimensions to choose from. I used 300 dimensional embeddings. \n",
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6UeNbZVxiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map the embeddings with the words of the text data\n",
        "embedding_dim = 300\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWBwnMbjlJud",
        "colab_type": "text"
      },
      "source": [
        "#**Training** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBzay1SGhyWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to compute F1 score. I use it as a metrics for Binary Classification.\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.backend as K\n",
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCu9QH4RlE65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Customized layer for weighted sum\n",
        "class WeightedSum(tf.keras.layers.Layer):\n",
        "    def __init__(self, a, **kwargs):\n",
        "        self.a = a\n",
        "        super(WeightedSum, self).__init__(**kwargs)\n",
        "    def call(self, model_outputs):\n",
        "        return self.a * model_outputs[0] + (1 - self.a) * model_outputs[1]\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSUC5RIBhLos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text+audio Conatenation fusion model\n",
        "# For using text only model, uncomment the out1 layer. Provide the suitable units inside the Dense layer.\n",
        "# For Binary classification, use 1 and 'sigmoid' as activation\n",
        "# For 7 class classification, use 7 and 'softmax' as activation\n",
        "# For Regression, use 1 and remove activation\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# text only model\n",
        "inp1 = Input(max_length)   \n",
        "layer = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False)(inp1)            \n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer)\n",
        "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
        "#out1 = tf.keras.layers.Dense(1, activation='sigmoid')(layer)                 \n",
        "model1= Model(inp1,layer)                                 \n",
        "\n",
        "# audio model\n",
        "inp2 = Input((57,1639))           # Dimensions for MFCC data. For VGGish, change it to (128,858)\n",
        "layer2 = tf.keras.layers.Conv1D(64,3,activation='relu',input_shape=(57,1639))(inp2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu',padding='same')(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(256,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(256,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(64,activation='relu')(layer2)\n",
        "#layer2 = tf.keras.layers.Dropout(0.5)(layer2)\n",
        "model2 = Model(inp2,layer2)\n",
        "\n",
        "# Fusion of the two models. I concatenate the two models and pass it through a projection layer. Bothe the text and audio models output 64 dimensional vectors\n",
        "# So the dense layer has 128 units\n",
        "fusion = tf.keras.layers.Concatenate(axis=1)([model1.output, model2.output])    \n",
        "fusion = tf.keras.layers.Dense(128,activation='relu')(fusion)\n",
        "#fusion = tf.keras.layers.Dropout(0.5)(fusion)\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(fusion)        #For binary classification. For 7 class, change it to 7 and 'softmax'   \n",
        "#out = tf.keras.layers.Dense(1)(fusion)      #uncomment for regression. comment the above line\n",
        "\n",
        "model3 = Model([model1.input,model2.input],out)             #the fused model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K7pB9tpWnv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')  #to reduce learning rate by factor of 0.1 if model performance degrades for 10 (patience) epochs.  \n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')  #early stopping if performance of model degrades for 10 epochs\n",
        "\n",
        "#Uncomment one of the next three lines at a time\n",
        "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy',f1_score])                #Binary classification\n",
        "#model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model3.compile(loss=\"mean_absolute_error\",optimizer='adam',metrics=[\"mean_absolute_error\"])             #Regression\n",
        "\n",
        "# I am training for 50 epochs with a batch size of 256. Set verbose to 2 for no training details and 0 for more training details.\n",
        "num_epochs = 50\n",
        "history1=model3.fit([train_padded,train_audio], \n",
        "                    train_labels, \n",
        "                    epochs=num_epochs, \n",
        "                    batch_size=256, \n",
        "                    validation_data=([val_padded,val_audio],val_labels),\n",
        "                    callbacks=[reduce],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDamnIVACffG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text+audio weighted sum of logits fusion model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#text model\n",
        "inp1 = Input(max_length)   \n",
        "layer = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False)(inp1)            \n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer)\n",
        "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
        "out1 = tf.keras.layers.Dense(1)(layer)                  #Use 7 for 7 class classification. Do not change for binary classification and regression\n",
        "model1= Model(inp1,out1)\n",
        "\n",
        "#audio model\n",
        "inp2 = Input((128,858))\n",
        "layer2 = tf.keras.layers.Conv1D(64,3,activation='relu',input_shape=(128,858))(inp2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu',padding='same')(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(256,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(256,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(64,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "out2 = tf.keras.layers.Dense(1)(layer2)                         #Use 7 for 7 class classification. Do not change for binary classification and regression\n",
        "model2 = Model(inp2,out2)\n",
        "\n",
        "# 0.5 in the next line mean 50% weightage to both modalities\n",
        "fusion = WeightedSum(0.5)([model1.output, model2.output])\n",
        "\n",
        "#For regression, comment both the lines\n",
        "out = tf.keras.layers.Activation('sigmoid')(fusion)             \n",
        "#out = tf.keras.layers.Activation('softmax')(fusion)            #uncomment for 7 class classification\n",
        "     \n",
        "\n",
        "model3 = Model([model1.input,model2.input],out)             # for regression, change 'out' to 'fusion'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}