{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Attack_Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM7PUW4caG1Hxnm534e+3mU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/Text_Attack_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0JCG5RxLDk",
        "colab_type": "text"
      },
      "source": [
        "## **Twitter Sentiment Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy-64GNwGF6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K17tXWVDYAB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading the Datasets (https://www.kaggle.com/kazanova/sentiment140)\n",
        "!wget --no-check-certificate \\\n",
        "      \"https://storage.googleapis.com/kaggle-data-sets/2477%2F4140%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1595795502&Signature=RL%2B0kDJFHl%2Be5wEpXrHiJdkJ7FXXqIIiO%2B4LAzsK59KjW89xILFBwgCRn2M1MCiNPKiYTB469Y%2FeR17sXFlyF4sX6wB4bidNdqdLr9p%2F38MQiHRdbU%2BYpWa4R0pCmwYIzS%2BySdVAYh8dA8HhDKwo3STpaeLjENdtw%2BXtFcOfuKHOZx08YRi1UbOk5NxE15DA1c%2FTJDUF5lZype4okBqiMmr7x3qoHjBrQzcC7n60%2F1ZTmf14Htov%2BnXa6qdEBcfSoDfmBXrruegwBdFodSDkeVulE%2FirVN%2BOK%2BCVVYFEqJ85XOLQd64TtxZJmnxD%2BKuJRcPMVCn0s72bMmbRBejdsA%3D%3D\"\\\n",
        "      -O \"/content/sentiment_tweets.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvzPou5mY--T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/sentiment_tweets.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWaXFaGYEkbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df=pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding=\"ISO-8859-1\",names = [\"label\", \"ids\", \"date\", \"flag\", \"user\", \"tweets\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTNEHXZ8JWwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar([0,1], df['label'].value_counts(), width=0.5, bottom=None, align='center', data=df)\n",
        "plt.title('Labels Distribution')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(np.arange(0, 1, step=2))\n",
        "print('Labels Distribution:\\n',df['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjzjTwU9JYO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Functions for Preprocessing the Dataset\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def mystopwords(text):\n",
        "    return ' '.join([w for w in word_tokenize(text) if not w in stop_words])\n",
        "\n",
        "def lemmatize(text):\n",
        "    return ' '.join([Word(word).lemmatize() for word in text.split()])\n",
        "\n",
        "import re\n",
        "def preprocess(text):\n",
        "    # Remove link,user and special characters\n",
        "    text = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "          tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4aQVy0Gab10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning the train data and separating the texts and labels\n",
        "tweets=[]\n",
        "labels=[]\n",
        "for i in range(len(df)):\n",
        "  if df['label'][i]==4:\n",
        "    labels.append(1)\n",
        "  else:\n",
        "    labels.append(0)\n",
        "  tweets.append(preprocess(df['tweets'][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEAMVaW9bDB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example of a tweet before and after cleaning\n",
        "print('Tweet before cleaning: ',df['tweets'][100])\n",
        "print('Tweet after cleaning: ',tweets[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyENeeIDdEse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Suffling the data and splitting the data into train and test sets (80:20)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_tweets, val_tweets, train_labels, val_labels= train_test_split(tweets, labels, test_size=0.2, shuffle= True,random_state=42)\n",
        "#test_tweets = val_tweets[:250]\n",
        "#test_labels = val_labels[:250]\n",
        "val_tweets, test_tweets, val_labels, test_labels= train_test_split(val_tweets, val_labels, test_size=0.001, shuffle= True,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBOlRkmDdj2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Summary\n",
        "print('Length of the Training Set: ',len(df))\n",
        "print('No. of Training Examples: ',len(train_tweets))\n",
        "print('No. of Validation Examples: ',len(val_tweets))\n",
        "print('No. of Test Examples: ',len(test_tweets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7_LJhsUNpMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the text data. Similar to the audio data, segments of the text data are paddded to have same length\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 40\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_len=50000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_len+1,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(tweets)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "print('Size of Vocabulary: ',vocab_size)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_tweets)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_tweets)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_tweets)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_labels=np.expand_dims(train_labels, axis=1)\n",
        "val_labels=np.expand_dims(val_labels, axis=1)\n",
        "test_labels=np.expand_dims(test_labels, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7-McSITMp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Statistics\n",
        "print('Dimension of Training Data: ',train_padded.shape)\n",
        "print('Dimension of Validation Data: ',val_padded.shape)\n",
        "print('Dimension of Test Data: ',test_padded.shape)\n",
        "print('Dimension of Training Labels: ',train_labels.shape)\n",
        "print('Dimension of Validation Labels: ',val_labels.shape)\n",
        "print('Dimension of Test Labels: ',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1VdIclHTXIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download Glove Wiki Embeddings\n",
        "!wget --no-check-certificate \\\n",
        "      \"http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\"\\\n",
        "      -O \"/content/drive/My Drive/mosi_data/globe6B.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvljIHkqUHiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the downloaded embeddings\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/globe6B.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r03B041VDGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the embeddings. There are 4 dimensions to choose from. I used 300 dimensional embeddings. \n",
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6UeNbZVxiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map the embeddings with the words of the text data\n",
        "embedding_dim = 300\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWBwnMbjlJud",
        "colab_type": "text"
      },
      "source": [
        "#**Training** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBzay1SGhyWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to compute F1 score. I use it as a metrics for Binary Classification.\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.backend as K\n",
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSUC5RIBhLos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provide the suitable units inside the Dense layer.\n",
        "# For Binary classification, use 1 and 'sigmoid' as activation\n",
        "# For 7 class classification, use 7 and 'softmax' as activation\n",
        "# For Regression, use 1 and remove activation\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# text only model\n",
        "inp = Input(max_length)   \n",
        "layer = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False)(inp)            \n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer)\n",
        "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
        "#out = tf.keras.layers.Dense(1, activation='sigmoid')(layer) \n",
        "out = tf.keras.layers.Dense(2, activation='softmax')(layer) \n",
        "#out = tf.keras.layers.Dense(1)(layer)                 \n",
        "model= Model(inp,out)                                 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K7pB9tpWnv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')  #to reduce learning rate by factor of 0.1 if model performance degrades for 10 (patience) epochs.  \n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True,monitor='val_accuracy', min_delta=1e-4,mode='max')  #early stopping if performance of model degrades for 10 epochs\n",
        "\n",
        "#Uncomment one of the next three lines at a time\n",
        "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy',f1_score])                #Binary classification\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model.compile(loss=\"mean_absolute_error\",optimizer='adam',metrics=[\"mean_absolute_error\"])             #Regression\n",
        "\n",
        "# I am training for 50 epochs with a batch size of 256. Set verbose to 2 for no training details and 0 for more training details.\n",
        "history = model.fit(train_padded, train_labels, batch_size=4096, epochs=5, validation_data=(val_padded,val_labels),shuffle=True,callbacks=[reduce,earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52lbT4fu4RjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test Accuracy\n",
        "results = model.evaluate(x=test_padded,y=test_labels)\n",
        "print('Test Set Performance: ',results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Iy5BnkB7ac",
        "colab_type": "text"
      },
      "source": [
        "## **Attack**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np7Zy-l2haQR",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english'))\n",
        "from absl import logging\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "mode = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "\n",
        "def embed(input):\n",
        "  return mode(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUUnpMfJhdzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "#model1 = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz (Unzipped Files)/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/fasttext_wiki.zip'\n",
        "similarity_model = KeyedVectors.load_word2vec_format('/content/wiki-news-300d-1M.vec', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6YG4M54hdqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_word_saliency(model,val_reviews,val_padded,val_labels):\n",
        "    candidates = {}\n",
        "    outer = tqdm(total=len(val_reviews), desc='Evaluating Word Saliency', position=0)\n",
        "    for j,sent in enumerate(val_reviews):\n",
        "        outer.update(1)\n",
        "        sent = sent.split()\n",
        "        score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "        pred = np.argmax(score)\n",
        "\n",
        "        if pred==val_labels[j]:\n",
        "          mask = np.zeros(40)\n",
        "          mask[:len(sent)]=1\n",
        "          dic = {}\n",
        "          for i,word in enumerate(sent):\n",
        "            if word not in stop_words:\n",
        "              mask[i] = 0\n",
        "              inp = mask*val_padded[j]\n",
        "              score_new = model.predict(inp.reshape(1,-1))[0]\n",
        "              pred_new = np.argmax(score_new)\n",
        "              if pred_new == pred:\n",
        "                imp = score[pred] - score_new[pred_new]\n",
        "              else:\n",
        "                  imp = (score[pred] - score_new[pred]) + (score_new[pred_new] - score[pred_new])\n",
        "              mask[i] = 1\n",
        "              if imp>0:\n",
        "                dic[word] = imp\n",
        "          if dic:\n",
        "            k = sorted(dic.keys(),key = dic.get,reverse=True)\n",
        "            if len(k)>3:\n",
        "              candidates[j] = k[:3]\n",
        "            else:\n",
        "              candidates[j] = k\n",
        "\n",
        "    return candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYHooRPQhdhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_words(model,val_reviews,val_padded,val_labels,candidates,model1,embed):\n",
        "      \n",
        "      new_candidates = {}\n",
        "\n",
        "      outer = tqdm(total=len(candidates), desc='Finding Similar Words', position=0)\n",
        "      for j,sent in enumerate(val_reviews):\n",
        "        if j in candidates:\n",
        "            outer.update(1)\n",
        "            sent = sent.split()\n",
        "            dic = {}\n",
        "            score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "            pred = np.argmax(score)\n",
        "            for i,word in enumerate(sent):\n",
        "              if word in candidates[j]:\n",
        "                n = []\n",
        "                try:\n",
        "                  l = model1.most_similar(word,topn=50)\n",
        "                except:\n",
        "                  pass\n",
        "\n",
        "                mini = float('inf')\n",
        "                we = None \n",
        "                for w in l:\n",
        "                  if w[0].lower()!=word:\n",
        "                    arr = sent[:]\n",
        "                    arr[i] = w[0].lower()\n",
        "                    k = tokenizer.texts_to_sequences([\" \".join(arr)])\n",
        "                    inp = pad_sequences(k, maxlen=40, padding='post', truncating='post')\n",
        "                    score_new = model.predict(inp)[0]\n",
        "                    pred_new = np.argmax(score_new)\n",
        "                    if pred_new !=pred:\n",
        "                      message_embeddings = embed([\" \".join(arr),\" \".join(sent)])\n",
        "                      score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                      if score1>0.7:\n",
        "                          n.append(w[0].lower())\n",
        "                    else:\n",
        "                      if score_new[pred]<mini:\n",
        "                            mini = score_new[pred]\n",
        "                            we = w[0].lower()\n",
        "                if we:\n",
        "                  arr = sent[:]\n",
        "                  arr[i] = we\n",
        "                  message_embeddings = embed([\" \".join(arr),\" \".join(sent)])\n",
        "                  score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                  if score1>0.7:\n",
        "                    n.append(we)\n",
        "                if n:\n",
        "                  dic[word] = n[:]\n",
        "            if dic:\n",
        "                new_candidates[j] = dic \n",
        "\n",
        "      return new_candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozPZAh1LhdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_adversary(model,val_reviews,val_padded,val_labels,new_candidates,embed):\n",
        "    adversary = {}\n",
        "\n",
        "    outer = tqdm(total=len(new_candidates), desc='Generating Adversarial Samples', position=0)\n",
        "    for j,sent in enumerate(val_reviews):\n",
        "      if j in new_candidates:\n",
        "        outer.update(1)\n",
        "        sent = sent.split()\n",
        "        score = model.predict(val_padded[j].reshape(1,-1))[0]\n",
        "        pred = np.argmax(score)\n",
        "        a = []\n",
        "        arr = sent[:]\n",
        "        flag = 0\n",
        "        for i,word in enumerate(sent):\n",
        "          if word in new_candidates[j]:\n",
        "            \n",
        "            mini = float('inf')\n",
        "            we = None\n",
        "            \n",
        "            for w in new_candidates[j][word]:\n",
        "              if w:\n",
        "                s = arr[i]\n",
        "                arr[i] = w.lower()\n",
        "                k = tokenizer.texts_to_sequences([\" \".join(arr)])\n",
        "                inp = pad_sequences(k, maxlen=40, padding='post', truncating='post')\n",
        "                score_new = model.predict(inp)[0]\n",
        "                pred_new = np.argmax(score_new)\n",
        "                if pred_new !=pred:\n",
        "                  arr1 = sent[:]\n",
        "                  arr1[i] = w.lower()\n",
        "                  message_embeddings = embed([\" \".join(arr1),\" \".join(sent)])\n",
        "                  score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                  if score1>0.7:\n",
        "                      arr = sent[:]\n",
        "                      arr[i] = w.lower()\n",
        "                      flag=1\n",
        "                      break\n",
        "                else:\n",
        "                    \n",
        "                    if  abs(score[pred] - score_new[pred])>0.4:\n",
        "                        arr1 = sent[:]\n",
        "                        arr1[i] = w.lower()\n",
        "                        message_embeddings = embed([\" \".join(arr1),\" \".join(sent)])\n",
        "                        score1 =sklearn.metrics.pairwise.cosine_similarity(np.array(message_embeddings[0]).reshape(1,-1),np.array(message_embeddings[1]).reshape(1,-1))[0][0]\n",
        "                        if score1>0.7:\n",
        "                              arr = sent[:]\n",
        "                              arr[i] = w.lower()\n",
        "                              flag = 1\n",
        "                              break\n",
        "                    else:\n",
        "                      arr[i] = s\n",
        "                      if score_new[pred]<mini:\n",
        "                          mini = score_new[pred]\n",
        "                          we = w.lower()\n",
        "            if flag:\n",
        "              break\n",
        "            if we:\n",
        "              arr[i] = we\n",
        "        adversary[j] = \" \".join(arr)\n",
        "\n",
        "    adver = []\n",
        "\n",
        "    for i in range(len(val_reviews)):\n",
        "      if i in adversary:\n",
        "        adver.append(adversary[i])\n",
        "      else:\n",
        "        adver.append(val_reviews[i])\n",
        "\n",
        "    return adver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRpsfiJnhdQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candidates = evaluate_word_saliency(model,test_tweets,test_padded,test_labels)\n",
        "new_candidates = find_similar_words(model,test_tweets,test_padded,test_labels,candidates,similarity_model,embed)\n",
        "adversary = generate_adversary(model,test_tweets,test_padded,test_labels,new_candidates,embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPW6MAAsx_9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_seq = tokenizer.texts_to_sequences(adversary)\n",
        "test_pad = pad_sequences(test_seq, maxlen=40, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg8EvuI6hdNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results1 = model.evaluate(x=test_padded,y=test_labels)\n",
        "print('Test Set Performance: ',results1)\n",
        "results2 = model.evaluate(x=test_pad,y=test_labels)\n",
        "print('Test Set Performance after Attack: ',results2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9tfhTpzDUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_candidates.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Uz4_n7zChw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 50\n",
        "print('Adversary: ',adversary[index])\n",
        "k = tokenizer.texts_to_sequences([adversary[index]])\n",
        "k = pad_sequences(k, maxlen=40, padding='post', truncating='post')\n",
        "results = model.predict(x=k)\n",
        "print('Adversary Prediction: ',np.argmax(results))\n",
        "\n",
        "print('Original: ',test_tweets[index])\n",
        "k1 = tokenizer.texts_to_sequences([test_tweets[index]])\n",
        "k1 = pad_sequences(k1, maxlen=40, padding='post', truncating='post')\n",
        "results2 = model.predict(x=k1)\n",
        "print('Original Prediction: ',np.argmax(results2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}