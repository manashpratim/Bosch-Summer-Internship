{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoV1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTnOOxdaW2gDf+NtUHVWT/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/VideoV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkPTMabrU9Gf",
        "colab_type": "text"
      },
      "source": [
        "### Data is available at https://drive.google.com/drive/folders/1NFYIaXjL8V5kvZo3g9JEafLQ3scslWic?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZfcACENVGwc",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is for video (feature) extraction for the models in VideoV2 notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKVCC7yHCAq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHWPHH-P1jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/mosi_data/mosi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q-mvdXkDldm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mtcnn\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y92PZsSYTtaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras_vggface\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import numpy as np \n",
        "import cv2\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from keras_vggface.vggface import VGGFace\n",
        "model = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "from keras_vggface.utils import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB3qK5crQiXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_face(pixels):\n",
        "    detector = MTCNN()\n",
        "    results = detector.detect_faces(pixels)\n",
        "    if results:\n",
        "      x1, y1, width, height = results[0]['box']\n",
        "      x2, y2 = x1 + width, y1 + height\n",
        "      face = pixels[y1:y2, x1:x2]\n",
        "    else:\n",
        "      face=pixels\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize((100,100))\n",
        "      face = np.array(image)/255.\n",
        "      return face.astype('float32')\n",
        "    except:\n",
        "      return []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya37uUK-Qi81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(samples):\n",
        "\t#samples = preprocess_input(samples, version=2)\n",
        "\treturn model.predict(samples).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486DUV4CQ1f1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 1\n",
        "def extract_face_from_video1(videofile,video_dims=None,framerate=0.5):\n",
        "    vidcap = cv2.VideoCapture(videofile)\n",
        "    def getFrame(sec):\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "        hasFrames,image = vidcap.read()\n",
        "        if hasFrames:\n",
        "            if video_dims:\n",
        "              image =  cv2.resize(image, video_dims)\n",
        "            return image\n",
        "        else:\n",
        "          return []\n",
        "\n",
        "    sec = 0\n",
        "    framerate = framerate\n",
        "    frames = []\n",
        "    while True:\n",
        "        sec = sec + framerate\n",
        "        sec = round(sec, 2)\n",
        "        im = getFrame(sec)\n",
        "        if len(im)>0:\n",
        "          im = extract_face(im[...,::-1])   \n",
        "          frames.append(im)\n",
        "        else:\n",
        "          break\n",
        "    return np.array(frames).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3hgrnaOQ4il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 2 \n",
        "ef extract_face_from_video2(videofile,video_dims=None,framerate=0.1):\n",
        "    vidcap = cv2.VideoCapture(videofile)\n",
        "    def getFrame(sec):\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "        hasFrames,image = vidcap.read()\n",
        "        if hasFrames:\n",
        "            if video_dims:\n",
        "              image =  cv2.resize(image, video_dims)\n",
        "            return image\n",
        "        else:\n",
        "          return []\n",
        "\n",
        "    sec = 0\n",
        "    framerate = framerate\n",
        "    frames = []\n",
        "    while True:\n",
        "        sec = sec + framerate\n",
        "        sec = round(sec, 2)\n",
        "        im = getFrame(sec)\n",
        "        if len(im)>0:\n",
        "          im = (im[...,::-1]/255.).astype('float32')\n",
        "          frames.append(im)\n",
        "        else:\n",
        "          break\n",
        "\n",
        "    return np.array(frames).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OurgzUYcQ6UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 3\n",
        "def extract_face_from_video3(videofile,video_dims=None,framerate=0.03):\n",
        "    vidcap = cv2.VideoCapture(videofile)\n",
        "    def getFrame(sec):\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "        hasFrames,image = vidcap.read()\n",
        "        if hasFrames:\n",
        "            if video_dims:\n",
        "              image =  cv2.resize(image, video_dims)\n",
        "            return image\n",
        "        else:\n",
        "          return []\n",
        "\n",
        "    sec = 0\n",
        "    framerate = framerate\n",
        "    frames = []\n",
        "    while True:\n",
        "        sec = sec + framerate\n",
        "        sec = round(sec, 2)\n",
        "        im = getFrame(sec)\n",
        "        if len(im)>0:\n",
        "          im = (im[...,::-1]/255.).astype('float32')        \n",
        "          frames.append(im)\n",
        "        else:\n",
        "          break\n",
        "    return get_embeddings(np.array(frames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3V-NxAcQ-EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(img):\n",
        "  pyplot.imshow(img)\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbq0TOkmRC3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 1\n",
        "def visual_features1(mypath,files):\n",
        "    video_dic = {}\n",
        "    for file in files:\n",
        "      videofile = mypath+'/'+file+'.mp4'\n",
        "      samples = extract_face_from_video1(videofile)\n",
        "      video_dic[file] = get_embeddings(samples)\n",
        "      del samples\n",
        "    return video_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaRR4akRVkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 2\n",
        "def visual_features2(mypath,files):\n",
        "    video_dic = {}\n",
        "    for file in files:\n",
        "      videofile = mypath+'/'+file+'.mp4'\n",
        "      video_dic[file] = extract_face_from_video2(videofile,(64,64))\n",
        "      \n",
        "    return video_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mP0uqrKRwGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Model 3\n",
        "def visual_features3(mypath,files):\n",
        "    video_dic = {}\n",
        "    for file in files:\n",
        "      videofile = mypath+'/'+file+'.mp4'\n",
        "      video_dic[file] = extract_face_from_video3(videofile,(224,224))\n",
        "      \n",
        "    return video_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl5dU3U6Q0mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_file_names(mypath,savefile):\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  onlyfiles = [f[:f.find('.')] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  with open(savefile, 'w') as f:\n",
        "    for item in onlyfiles:\n",
        "        f.write(item)\n",
        "        f.write('\\n')\n",
        "  return onlyfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5MdzhrVT8dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mypath = '/content/Raw/Video/Segmented'\n",
        "files = get_file_names(mypath,'mosi_files.txt')\n",
        "video_dic = visual_features3(mypath,files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lj41znHUDGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Format Alignment\n",
        "dic1 = {}\n",
        "for file in files:\n",
        "  new = file[:-file[::-1].find('_')-1]\n",
        "  dic1[file] = new\n",
        "\n",
        "newdic = {}\n",
        "newdic1 = {}\n",
        "for key in dic1:\n",
        "  newkey = dic1[key]\n",
        "  if newkey not in newdic:\n",
        "    newdic[newkey] = {}\n",
        "  if newkey not in newdic1:\n",
        "    newdic1[newkey] = {}\n",
        "  newdic1[newkey][key] = video_dic[key]\n",
        "  k = key[-key[::-1].find('_'):]\n",
        "  newdic[newkey][int(k)] = video_dic[key]\n",
        "\n",
        "nd = {}\n",
        "for key in newdic:\n",
        "    nd[key] = []\n",
        "    for k in sorted(newdic[key].keys()):\n",
        "      nd[key].append(newdic[key][k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vGFQWYoUV8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/mosi_data/video_frames_dense.pickle', 'wb') as handle:\n",
        "    pickle.dump(nd, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}