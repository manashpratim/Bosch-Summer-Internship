{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A+V+T_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPDI44QLvZoZ0sR5y2vdRbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Bosch-Summer-Internship/blob/master/A%2BV%2BT_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL5yItNOEWmL",
        "colab_type": "text"
      },
      "source": [
        "### Data is available at https://drive.google.com/drive/folders/1NFYIaXjL8V5kvZo3g9JEafLQ3scslWic?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i-moPO0D3gw",
        "colab_type": "text"
      },
      "source": [
        "## **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqNRUIuN66rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvjUg_XG7PQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/mosi_data/mosi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7ywkSa7cH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to get the file names. Inputs are path and name of the file to be saved\n",
        "def get_file_names(mypath,savefile):\n",
        "  from os import listdir\n",
        "  from os.path import isfile, join\n",
        "  onlyfiles = [f[:f.find('.')] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  with open(savefile, 'w') as f:\n",
        "    for item in onlyfiles:\n",
        "        f.write(item)\n",
        "        f.write('\\n')\n",
        "  return onlyfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-5N4HFp7gsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mypath = '/content/Raw/Transcript/Segmented'\n",
        "files = get_file_names(mypath,'textfile.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HFxnx0o7jf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/mosi_data/labels_joined.pickle', 'rb') as handle:\n",
        "    label= pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/mosi_data/text_data_joined.pickle', 'rb') as handle:\n",
        "    dic = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/mosi_data/audio_features_joined.pickle', 'rb') as handle:\n",
        "    dic2 = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/My Drive/mosi_data/video_features.pickle', 'rb') as handle:\n",
        "    dic3 = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15hpBc2MEe68",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYforFti7y5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the segments of the text data into a numpy array\n",
        "import numpy as np\n",
        "review = []\n",
        "for key in files:\n",
        "  review+=dic[key]\n",
        "review = np.array(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5XjDw-873qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the labels into a numpy array\n",
        "import numpy as np\n",
        "y = []\n",
        "for key in files:\n",
        "    y+=label[key]\n",
        "y = np.array(y)\n",
        "\n",
        "y[y>0]=1        #Convert labels to binary\n",
        "y[y<0]=0\n",
        "\n",
        "y=y.astype(int)   # Execute this line for classification. Comment it for regression\n",
        "#ref = {-3:0,-2:1,-1:2,0:3,1:4,2:5,3:6}         #Uncomment the following three lines for 7 class classification\n",
        "#for i,num in enumerate(y):\n",
        "#  y[i] = ref[num]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJr9zgTm771b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block pads the audio features so that each segments have same length. I use zero padding\n",
        "audio_data = []\n",
        "maximum = float('-inf')\n",
        "max_pad_len = 1639                            #max length of a sequence. For audio_features_joined (MFCC), use this\n",
        "#max_pad_len = 858                            #For audio_pretrained_features_joined (VGGish), use this. Uncomment the above\n",
        "\n",
        "for key in files:\n",
        "  for l in dic2[key]:\n",
        "\n",
        "    if len(l)>0:\n",
        "      #maximum = max(maximum,l.shape[0])\n",
        "      pad_width = max_pad_len - l.shape[0]\n",
        "      mfcc = np.pad(l.T, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "      audio_data.append(mfcc)\n",
        "    else:                                     # This else statement is for the VGGish features data. They have 28 bad frames. It does not affect the MFCC data\n",
        "      f = np.random.rand(128,858)               \n",
        "      audio_data.append(f)\n",
        "\n",
        "audio_data = np.array(audio_data)\n",
        "audio_data= audio_data.reshape(audio_data.shape[0], 57, 1639)             # For audio_features_joined\n",
        "#audio_data= audio_data.reshape(audio_data.shape[0], 128, 858)            # For audio_pretrained_features_joined\n",
        "#audio_data = audio_data.swapaxes(1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4iQu3Oj732J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block pads the video features so that each segments have same length. I use zero padding\n",
        "video_data = []\n",
        "#maximum = float('-inf')\n",
        "max_pad_len = 77                            #max length of a sequence\n",
        "                          \n",
        "\n",
        "for key in files:\n",
        "  for l in dic3[key]:\n",
        "    l = np.array(l)\n",
        "    if len(l)>0:\n",
        "      #maximum = max(maximum,l.shape[0])\n",
        "      pad_width = max_pad_len - l.shape[0]\n",
        "      mfcc = np.pad(l.T, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "      video_data.append(mfcc)\n",
        "    else:                                     # This else statement is for the VGGish features data. They have 28 bad frames. It does not affect the MFCC data\n",
        "      f = np.random.rand(512,77)               \n",
        "      video_data.append(f)\n",
        "\n",
        "video_data = np.array(video_data)\n",
        "video_data= video_data.reshape(video_data.shape[0], 512, 77,1) \n",
        "#video_data = video_data.swapaxes(1,-1)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNNcWh7t74E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to generate train-test split. Arguments are text data,labels,audio features data and split_size (0.8 mean 80:20 train-test split)\n",
        "def split_data(text,audio,video,labels,split_size=0.8):\n",
        "  import numpy as np  \n",
        "  train_length =int(len(labels)*split_size)\n",
        "  test_length =int(len(labels)-train_length)\n",
        "  idx = np.random.permutation(labels.shape[0])\n",
        "  text = text[idx]\n",
        "  audio = audio[idx]\n",
        "  video = video[idx]\n",
        "  labels = labels[idx]\n",
        "  text_train = text[:train_length]\n",
        "  text_val = text[train_length:]\n",
        "  labels_train = labels[:train_length]\n",
        "  labels_val = labels[train_length:]\n",
        "  audio_train = audio[:train_length]\n",
        "  audio_val = audio[train_length:]\n",
        "  video_train = video[:train_length]\n",
        "  video_val = video[train_length:]\n",
        "  \n",
        "  return text_train,text_val,audio_train,audio_val,video_train,video_val,labels_train,labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXey57mrBBdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get train-test split\n",
        "train_reviews, val_reviews, train_audio, val_audio, train_video,val_video,train_labels, val_labels = split_data(review,audio_data,video_data,y,0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRAeHPdbBEFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the text data. Similar to the audio data, segments of the text data are paddded to have same length\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 581\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_len=5000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_len+1,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(review)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "print('Size of Vocabulary: ',vocab_size)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_reviews)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_labels=np.expand_dims(train_labels, axis=1)\n",
        "val_labels=np.expand_dims(val_labels, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmT_7XwzBGwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the downloaded embeddings\n",
        "!unzip -q '/content/drive/My Drive/mosi_data/globe6B.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vJ7DQqSBIe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the embeddings. There are 4 dimensions to choose from. I used 300 dimensional embeddings. \n",
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n96f9-88BKZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map the embeddings with the words of the text data\n",
        "embedding_dim = 300\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9tqCDgdDDo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to compute F1 score. I use it as a metrics for Binary Classification.\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.backend as K\n",
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Kl1AS4Eqjc",
        "colab_type": "text"
      },
      "source": [
        "## **Baseline Late Fusion using Concatenation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8PiHSlKA6dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text+audio+video Conatenation fusion model\n",
        "# Provide the suitable units inside the Dense layer.\n",
        "# For Binary classification, use 1 and 'sigmoid' as activation\n",
        "# For 7 class classification, use 7 and 'softmax' as activation\n",
        "# For Regression, use 1 and remove activation\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# text model\n",
        "inp1 = Input(max_length)   \n",
        "layer = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False)(inp1)            \n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer)\n",
        "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
        "#out1 = tf.keras.layers.Dense(1, activation='sigmoid')(layer)                 \n",
        "model1= Model(inp1,layer)                                 \n",
        "\n",
        "# audio model\n",
        "inp2 = Input((57,1639))           \n",
        "layer2 = tf.keras.layers.Conv1D(64,3,activation='relu',input_shape=(57,1639))(inp2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu',padding='same')(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(256,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(256,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(64,activation='relu')(layer2)\n",
        "#layer2 = tf.keras.layers.Dropout(0.5)(layer2)\n",
        "model2 = Model(inp2,layer2)\n",
        "\n",
        "# video model\n",
        "inp3 = Input((512,77,1))           \n",
        "layer3 = tf.keras.layers.Conv2D(16,3,activation='relu',use_bias=False,input_shape=(512,77,1))(inp3)\n",
        "layer3 = tf.keras.layers.MaxPool2D(2)(layer3)\n",
        "layer3 = tf.keras.layers.Conv2D(32,3,use_bias=False,activation='relu')(layer3)\n",
        "layer3 = tf.keras.layers.MaxPool2D(2)(layer3)\n",
        "layer3 = tf.keras.layers.Conv2D(64,3,use_bias=False,activation='relu')(layer3)\n",
        "layer3 = tf.keras.layers.MaxPool2D(2)(layer3)\n",
        "layer3 = tf.keras.layers.Conv2D(128,3,use_bias=False,activation='relu')(layer3)\n",
        "layer3 = tf.keras.layers.MaxPool2D(2)(layer3)\n",
        "layer3 = tf.keras.layers.Dropout(0.3)(layer3)\n",
        "layer3 = tf.keras.layers.Flatten()(layer3)\n",
        "layer3 = tf.keras.layers.Dense(256,activation='relu')(layer3)\n",
        "layer3 = tf.keras.layers.Dropout(0.2)(layer3)\n",
        "layer3 = tf.keras.layers.Dense(64,activation='relu')(layer3)\n",
        "#layer2 = tf.keras.layers.Dropout(0.5)(layer2)\n",
        "model3 = Model(inp3,layer3)\n",
        "\n",
        "# Fusion of the two models. I concatenate the three models and pass it through a projection layer. All three models output 64 dimensional vectors\n",
        "# So the dense layer has 192 units\n",
        "fusion = tf.keras.layers.Concatenate(axis=1)([model1.output, model2.output,model3.output])   \n",
        "fusion = tf.keras.layers.Dense(192,activation='relu')(fusion)\n",
        "\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(fusion)        #For binary classification.  \n",
        "#out = tf.keras.layers.Dense(1)(fusion)                             #For regression. comment the above line\n",
        "#out = tf.keras.layers.Dense(7, activation='softmax')(fusion)       #For 7 class classification \n",
        "model = Model([model1.input,model2.input,model3.input],out)         #the fused model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6MEU5A074nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, mode='auto')  #to reduce learning rate by factor of 0.1 if model performance degrades for 10 (patience) epochs.  \n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')  #early stopping if performance of model degrades for 10 epochs\n",
        "\n",
        "#Uncomment one of the next three lines at a time\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy',f1_score])             #Binary classification\n",
        "#model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])            #7 class classifiaction\n",
        "#model.compile(loss=\"mean_absolute_error\",optimizer='adam',metrics=[\"mean_absolute_error\"])             #Regression\n",
        "\n",
        "# I am training for 50 epochs with a batch size of 256. Set verbose to 2 for no training details and 0 for more training details.\n",
        "num_epochs = 50\n",
        "history=model.fit([train_padded,train_audio,train_video], \n",
        "                    train_labels, \n",
        "                    epochs=num_epochs, \n",
        "                    batch_size=64, \n",
        "                    shuffle = True,\n",
        "                    validation_data=([val_padded,val_audio,val_video],val_labels),\n",
        "                    callbacks=[reduce],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oSAOIbZEznp",
        "colab_type": "text"
      },
      "source": [
        "## **Baseline A+T using Weighted Sum of Logits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICfy7g4d73w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Customized layer for weighted sum\n",
        "class WeightedSum(tf.keras.layers.Layer):\n",
        "    def __init__(self, a, **kwargs):\n",
        "        self.a = a\n",
        "        super(WeightedSum, self).__init__(**kwargs)\n",
        "    def call(self, model_outputs):\n",
        "        return self.a * model_outputs[0] + (1 - self.a) * model_outputs[1]\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9WS4tg73vN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text+audio weighted sum of logits fusion model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#text model\n",
        "inp1 = Input(max_length)   \n",
        "layer = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False)(inp1)            \n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer)\n",
        "layer = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer)\n",
        "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
        "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
        "out1 = tf.keras.layers.Dense(1)(layer)                  #Use 7 for 7 class classification. Do not change for binary classification and regression\n",
        "model1= Model(inp1,out1)\n",
        "\n",
        "#audio model\n",
        "inp2 = Input((128,858))\n",
        "layer2 = tf.keras.layers.Conv1D(64,3,activation='relu',input_shape=(128,858))(inp2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(128,3,activation='relu',padding='same')(layer2)\n",
        "layer2 = tf.keras.layers.Conv1D(256,3,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "layer2 = tf.keras.layers.MaxPool1D(2)(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(layer2)\n",
        "layer2 = tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128))(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(256,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.2)(layer2)\n",
        "layer2 = tf.keras.layers.Dense(64,activation='relu')(layer2)\n",
        "layer2 = tf.keras.layers.Dropout(0.3)(layer2)\n",
        "out2 = tf.keras.layers.Dense(1)(layer2)                         #Use 7 for 7 class classification. Do not change for binary classification and regression\n",
        "model2 = Model(inp2,out2)\n",
        "\n",
        "# 0.5 in the next line mean 50% weightage to both modalities\n",
        "fusion = WeightedSum(0.5)([model1.output, model2.output])\n",
        "\n",
        "#For regression, comment both the lines\n",
        "out = tf.keras.layers.Activation('sigmoid')(fusion)             \n",
        "#out = tf.keras.layers.Activation('softmax')(fusion)            #uncomment for 7 class classification\n",
        "     \n",
        "\n",
        "model3 = Model([model1.input,model2.input],out)             # for regression, change 'out' to 'fusion'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}